{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq + Attention with masking and packed padding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Machine Translation - Seq2Seq with Attention"
      ],
      "metadata": {
        "id": "K1LFCl_gQgCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download en_core_web_sm\n",
        "# !python -m spacy download de_core_news_sm\n",
        "# !pip install torchtext==0.9.1"
      ],
      "metadata": {
        "id": "hg2-l3G-Qbao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator"
      ],
      "metadata": {
        "id": "fA-8b2prkV3E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "5hfjt-BjkaMN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "pgc07ka7kYXX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_de = spacy.load('de_core_news_sm') #Tokenizer for german language\n",
        "spacy_en = spacy.load('en_core_web_sm')  #Tokenizer for english language"
      ],
      "metadata": {
        "id": "X-rYZ8dxTBvh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_de(text):\n",
        "    \"\"\"\n",
        "    Tokenizes German text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "metadata": {
        "id": "7Q4oMZ7gkkrQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using packed padded sequences, we need to tell PyTorch how long the actual (non-padded) sequences are. Luckily for us, TorchText's Field objects allow us to use the `include_lengths` argument, this will cause our `batch.src` to be a tuple. The first element of the tuple is the same as before, a batch of numericalized source sentence as a tensor, and the second element is the non-padded lengths of each source sentence within the batch."
      ],
      "metadata": {
        "id": "dCbEEP2LeW_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRC = Field(tokenize = tokenize_de, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            include_lengths = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)"
      ],
      "metadata": {
        "id": "0ZBWaqVSeWrF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
        "                                                    fields = (SRC, TRG))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb3tnXFOfGd-",
        "outputId": "0365fad3-af33-4ce7-d1df-fe1e1562b449"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading training.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 652kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading validation.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 171kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 167kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "metadata": {
        "id": "xQl93pdNfIbH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One quirk about packed padded sequences is that all elements in the batch need to be sorted by their non-padded lengths in descending order, i.e. the first sentence in the batch needs to be the longest. We use two arguments of the iterator to handle this, `sort_within_batch` which tells the iterator that the contents of the batch need to be sorted, and `sort_key` a function which tells the iterator how to sort the elements in the batch. Here, we sort by the length of the src sentence"
      ],
      "metadata": {
        "id": "IqBlhGY-fOmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_within_batch = True,\n",
        "     sort_key = lambda x : len(x.src),\n",
        "     device = device)"
      ],
      "metadata": {
        "id": "NwBOrpdrfKdM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "                \n",
        "        #need to explicitly put lengths on cpu!\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'))\n",
        "                \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "                                 \n",
        "        #packed_outputs is a packed sequence containing all hidden states\n",
        "        #hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "            \n",
        "        #outputs is now a non-packed sequence, all hidden states obtained\n",
        "        #  when the input is a pad token are all zeros\n",
        "            \n",
        "        #outputs = [src len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs are always from the last layer\n",
        "        \n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        #  encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "4Ul6HVrofVoX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat decoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "  \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden = [batch size, src len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        #energy = [batch size, src len, dec hid dim]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        #attention = [batch size, src len]\n",
        "        \n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)"
      ],
      "metadata": {
        "id": "UClPXMAtfYno"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #mask = [batch size, src len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "                \n",
        "        #a = [batch size, src len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "metadata": {
        "id": "c3qx7TdBfb_p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "                    \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "\n",
        "        #mask = [batch size, src len]\n",
        "                \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
        "            #  and mask\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "            \n",
        "        return outputs"
      ],
      "metadata": {
        "id": "C9XxRp4kfgLF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)"
      ],
      "metadata": {
        "id": "UzpER3l7fiUt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHst4Vtlfj8e",
        "outputId": "db80ce10-6aea-4424-fba3-eddd30bb884d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7853, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSRkvYO8fl-e",
        "outputId": "6f2d6e13-e0d5-4ef4-9278-078f7fa8aa02"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 20,518,405 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n"
      ],
      "metadata": {
        "id": "2yUhdrSefnjO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "tt_5d3ccfpLb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, src_len = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, src_len, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "0vyJjhL4frRD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, src_len = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, src_len, trg, 0) #turn off teacher forcing\n",
        "            \n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "MAV-NgoNftbl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "uHs7Wpgkfvot"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNDHASt6fxT2",
        "outputId": "ee9d07bd-86fe-48e7-bc46-71196076bbe6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 44s\n",
            "\tTrain Loss: 5.042 | Train PPL: 154.823\n",
            "\t Val. Loss: 4.779 |  Val. PPL: 118.930\n",
            "Epoch: 02 | Time: 0m 46s\n",
            "\tTrain Loss: 4.100 | Train PPL:  60.346\n",
            "\t Val. Loss: 4.159 |  Val. PPL:  64.029\n",
            "Epoch: 03 | Time: 0m 47s\n",
            "\tTrain Loss: 3.349 | Train PPL:  28.473\n",
            "\t Val. Loss: 3.601 |  Val. PPL:  36.631\n",
            "Epoch: 04 | Time: 0m 47s\n",
            "\tTrain Loss: 2.861 | Train PPL:  17.472\n",
            "\t Val. Loss: 3.353 |  Val. PPL:  28.584\n",
            "Epoch: 05 | Time: 0m 46s\n",
            "\tTrain Loss: 2.480 | Train PPL:  11.936\n",
            "\t Val. Loss: 3.239 |  Val. PPL:  25.514\n",
            "Epoch: 06 | Time: 0m 47s\n",
            "\tTrain Loss: 2.178 | Train PPL:   8.825\n",
            "\t Val. Loss: 3.233 |  Val. PPL:  25.354\n",
            "Epoch: 07 | Time: 0m 46s\n",
            "\tTrain Loss: 1.941 | Train PPL:   6.965\n",
            "\t Val. Loss: 3.147 |  Val. PPL:  23.255\n",
            "Epoch: 08 | Time: 0m 47s\n",
            "\tTrain Loss: 1.751 | Train PPL:   5.761\n",
            "\t Val. Loss: 3.232 |  Val. PPL:  25.332\n",
            "Epoch: 09 | Time: 0m 46s\n",
            "\tTrain Loss: 1.596 | Train PPL:   4.932\n",
            "\t Val. Loss: 3.241 |  Val. PPL:  25.556\n",
            "Epoch: 10 | Time: 0m 46s\n",
            "\tTrain Loss: 1.483 | Train PPL:   4.407\n",
            "\t Val. Loss: 3.265 |  Val. PPL:  26.176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut4-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjFMqd0Af1h1",
        "outputId": "7eaeb0e4-5ce3-4369-f503-d9efe27f4965"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 3.193 | Test PPL:  24.362 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('de')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    \n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    src_len = torch.LongTensor([len(src_indexes)])\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
        "\n",
        "    mask = model.create_mask(src_tensor)\n",
        "        \n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
        "\n",
        "        attentions[i] = attention\n",
        "            \n",
        "        pred_token = output.argmax(1).item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ],
      "metadata": {
        "id": "7nLifznxf4jK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_attention(sentence, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=15)\n",
        "    \n",
        "    x_ticks = [''] + ['<sos>'] + [t.lower() for t in sentence] + ['<eos>']\n",
        "    y_ticks = [''] + translation\n",
        "     \n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "bnFhWykmf6Sy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_idx = 12\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['src']\n",
        "trg = vars(train_data.examples[example_idx])['trg']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6weqEQEf77G",
        "outputId": "7ac78964-b2f1-4d3e-8231-16c184223bde"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['ein', 'schwarzer', 'hund', 'und', 'ein', 'gefleckter', 'hund', 'kämpfen', '.']\n",
            "trg = ['a', 'black', 'dog', 'and', 'a', 'spotted', 'dog', 'are', 'fighting']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR8lhErcf9V1",
        "outputId": "22059e71-db98-4d5a-aca9-fdb4dc4e999e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted trg = ['a', 'black', 'dog', 'and', 'spotted', 'spotted', 'dog', 'fighting', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_attention(src, translation, attention)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "vt_LRGBWf-3M",
        "outputId": "0ab37fff-f454-489a-9bb8-bd6963657c2c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    \n",
        "    for datum in data:\n",
        "        \n",
        "        src = vars(datum)['src']\n",
        "        trg = vars(datum)['trg']\n",
        "        \n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        \n",
        "        #cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        \n",
        "    return bleu_score(pred_trgs, trgs)"
      ],
      "metadata": {
        "id": "1APtXJHRgCGY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n",
        "\n",
        "print(f'BLEU score = {bleu_score*100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ-BfTW4gDwT",
        "outputId": "54a7bfab-3446-4787-87d4-9731a76d894e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score = 29.10\n"
          ]
        }
      ]
    }
  ]
}
